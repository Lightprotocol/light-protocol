use borsh::BorshSerialize;
use light_batched_merkle_tree::merkle_tree::{
    InstructionDataBatchAppendInputs, InstructionDataBatchNullifyInputs,
};
use light_client::rpc::Rpc;
use light_registry::account_compression_cpi::sdk::{
    create_batch_append_instruction, create_batch_nullify_instruction,
};
use solana_sdk::signer::Signer;
use tracing::{debug, instrument, info};

use super::{
    common::{send_transaction_batch, BatchContext, ParsedMerkleTreeData, ParsedQueueData},
    state_streams::prepare_proofs_with_sequential_changelogs,
};
use crate::Result;

/// Generate proofs for both nullify and append operations with proper changelog sequencing
/// This ensures append uses the changelogs generated by nullify while keeping proof generation parallel
#[instrument(
    level = "debug", 
    skip(context, merkle_tree_data, output_queue_data),
    fields(merkle_tree = ?context.merkle_tree)
)]
pub(crate) async fn prepare_and_generate_proofs_parallel<R: Rpc>(
    context: &BatchContext<R>,
    merkle_tree_data: ParsedMerkleTreeData,
    output_queue_data: ParsedQueueData,
) -> Result<(Vec<InstructionDataBatchNullifyInputs>, Vec<InstructionDataBatchAppendInputs>)> {
    info!("Preparing proofs with sequential changelog calculation and parallel proof generation");
    
    // This function will:
    // 1. Fetch queue elements for both operations in parallel
    // 2. Calculate nullify changelogs first
    // 3. Generate all ZKP proofs in parallel (both nullify and append)
    // 4. Return the proofs ready for submission
    let (nullify_proofs, append_proofs) = prepare_proofs_with_sequential_changelogs(
        context.rpc_pool.clone(),
        context.merkle_tree,
        context.prover_update_url.clone(),
        context.prover_append_url.clone(),
        context.prover_api_key.clone(),
        context.prover_polling_interval,
        context.prover_max_wait_time,
        merkle_tree_data,
        output_queue_data,
    ).await?;
    
    Ok((nullify_proofs, append_proofs))
}

/// Submit nullify transactions with pre-generated proofs
/// Each proof is sent in a separate transaction to handle root updates properly
#[instrument(
    level = "debug",
    skip(context, proofs),
    fields(merkle_tree = ?context.merkle_tree)
)]
pub(crate) async fn submit_nullify_transaction<R: Rpc>(
    context: &BatchContext<R>,
    proofs: Vec<InstructionDataBatchNullifyInputs>,
) -> Result<()> {
    if proofs.is_empty() {
        return Ok(());
    }
    
    // Send each proof in a separate transaction
    for (i, data) in proofs.iter().enumerate() {
        debug!("Submitting nullify proof {}/{}", i + 1, proofs.len());
        
        let instruction = create_batch_nullify_instruction(
            context.authority.pubkey(),
            context.derivation,
            context.merkle_tree,
            context.epoch,
            data.try_to_vec().unwrap(),
        );
        
        send_transaction_batch(context, vec![instruction]).await?;
        
        // Wait for indexer to catch up before sending next transaction
        if i < proofs.len() - 1 {
            let rpc = context.rpc_pool.get_connection().await?;
            forester_utils::utils::wait_for_indexer(&*rpc)
                .await
                .map_err(|e| anyhow::anyhow!("Indexer wait error: {:?}", e))?;
        }
    }
    
    Ok(())
}

/// Submit append transactions with pre-generated proofs
/// Each proof is sent in a separate transaction to handle root updates properly
#[instrument(
    level = "debug",
    skip(context, proofs),
    fields(merkle_tree = ?context.merkle_tree)
)]
pub(crate) async fn submit_append_transaction<R: Rpc>(
    context: &BatchContext<R>,
    proofs: Vec<InstructionDataBatchAppendInputs>,
) -> Result<()> {
    if proofs.is_empty() {
        return Ok(());
    }
    
    // Send each proof in a separate transaction
    for (i, data) in proofs.iter().enumerate() {
        debug!("Submitting append proof {}/{}", i + 1, proofs.len());
        
        let instruction = create_batch_append_instruction(
            context.authority.pubkey(),
            context.derivation,
            context.merkle_tree,
            context.output_queue,
            context.epoch,
            data.try_to_vec().unwrap(),
        );
        
        send_transaction_batch(context, vec![instruction]).await?;
        
        // Wait for indexer to catch up before sending next transaction
        if i < proofs.len() - 1 {
            let rpc = context.rpc_pool.get_connection().await?;
            forester_utils::utils::wait_for_indexer(&*rpc)
                .await
                .map_err(|e| anyhow::anyhow!("Indexer wait error: {:?}", e))?;
        }
    }
    
    Ok(())
}
