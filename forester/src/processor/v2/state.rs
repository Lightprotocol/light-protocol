use borsh::BorshSerialize;
use futures::StreamExt;
use light_batched_merkle_tree::merkle_tree::{
    InstructionDataBatchAppendInputs, InstructionDataBatchNullifyInputs,
};
use light_client::rpc::Rpc;
use light_registry::account_compression_cpi::sdk::{
    create_batch_append_instruction, create_batch_nullify_instruction,
};
use solana_program::instruction::Instruction;
use solana_sdk::signer::Signer;
use tracing::{instrument, info};

use super::{
    common::{process_stream, send_transaction_batch, BatchContext, ParsedMerkleTreeData, ParsedQueueData},
    state_streams::{get_append_instruction_stream, get_nullify_instruction_stream, 
                     prepare_proofs_with_sequential_changelogs},
};
use crate::Result;

#[instrument(
    level = "debug",
    skip(context, merkle_tree_data),
    fields(merkle_tree = ?context.merkle_tree)
)]
pub(crate) async fn perform_nullify<R: Rpc>(
    context: &BatchContext<R>,
    merkle_tree_data: ParsedMerkleTreeData,
) -> Result<()> {
    let instruction_builder = |data: &InstructionDataBatchNullifyInputs| -> Instruction {
        create_batch_nullify_instruction(
            context.authority.pubkey(),
            context.derivation,
            context.merkle_tree,
            context.epoch,
            data.try_to_vec().unwrap(),
        )
    };

    let stream_future = async {
        let (stream, size) = get_nullify_instruction_stream(
            context.rpc_pool.clone(),
            context.merkle_tree,
            context.prover_update_url.clone(),
            context.prover_api_key.clone(),
            context.prover_polling_interval,
            context.prover_max_wait_time,
            merkle_tree_data,
        )
        .await?;
        let stream = stream.map(|item| item.map_err(anyhow::Error::from));
        Ok((stream, size))
    };

    process_stream(context, stream_future, instruction_builder).await?;
    Ok(())
}

#[instrument(
    level = "debug",
    skip(context, merkle_tree_data, output_queue_data),
    fields(merkle_tree = ?context.merkle_tree)
)]
pub(crate) async fn perform_append<R: Rpc>(
    context: &BatchContext<R>,
    merkle_tree_data: ParsedMerkleTreeData,
    output_queue_data: ParsedQueueData,
) -> Result<()> {
    let instruction_builder = |data: &InstructionDataBatchAppendInputs| -> Instruction {
        create_batch_append_instruction(
            context.authority.pubkey(),
            context.derivation,
            context.merkle_tree,
            context.output_queue,
            context.epoch,
            data.try_to_vec().unwrap(),
        )
    };

    let stream_future = async {
        let (stream, size) = get_append_instruction_stream(
            context.rpc_pool.clone(),
            context.merkle_tree,
            context.prover_append_url.clone(),
            context.prover_api_key.clone(),
            context.prover_polling_interval,
            context.prover_max_wait_time,
            merkle_tree_data,
            output_queue_data,
        )
        .await?;
        let stream = stream.map(|item| item.map_err(anyhow::Error::from));
        Ok((stream, size))
    };
    
    process_stream(context, stream_future, instruction_builder).await?;
    Ok(())
}

/// Generate proofs for both nullify and append operations with proper changelog sequencing
/// This ensures append uses the changelogs generated by nullify while keeping proof generation parallel
#[instrument(
    level = "debug", 
    skip(context, merkle_tree_data, output_queue_data),
    fields(merkle_tree = ?context.merkle_tree)
)]
pub(crate) async fn prepare_and_generate_proofs_parallel<R: Rpc>(
    context: &BatchContext<R>,
    merkle_tree_data: ParsedMerkleTreeData,
    output_queue_data: ParsedQueueData,
) -> Result<(Vec<InstructionDataBatchNullifyInputs>, Vec<InstructionDataBatchAppendInputs>)> {
    info!("Preparing proofs with sequential changelog calculation and parallel proof generation");
    
    // This function will:
    // 1. Fetch queue elements for both operations in parallel
    // 2. Calculate nullify changelogs first
    // 3. Generate all ZKP proofs in parallel (both nullify and append)
    // 4. Return the proofs ready for submission
    let (nullify_proofs, append_proofs) = prepare_proofs_with_sequential_changelogs(
        context.rpc_pool.clone(),
        context.merkle_tree,
        context.prover_update_url.clone(),
        context.prover_append_url.clone(),
        context.prover_api_key.clone(),
        context.prover_polling_interval,
        context.prover_max_wait_time,
        merkle_tree_data,
        output_queue_data,
    ).await?;
    
    Ok((nullify_proofs, append_proofs))
}

/// Submit nullify transaction with pre-generated proofs
#[instrument(
    level = "debug",
    skip(context, proofs),
    fields(merkle_tree = ?context.merkle_tree)
)]
pub(crate) async fn submit_nullify_transaction<R: Rpc>(
    context: &BatchContext<R>,
    proofs: Vec<InstructionDataBatchNullifyInputs>,
) -> Result<()> {
    if proofs.is_empty() {
        return Ok(());
    }
    
    let instructions: Vec<Instruction> = proofs
        .iter()
        .map(|data| create_batch_nullify_instruction(
            context.authority.pubkey(),
            context.derivation,
            context.merkle_tree,
            context.epoch,
            data.try_to_vec().unwrap(),
        ))
        .collect();
    
    send_transaction_batch(context, instructions).await?;
    Ok(())
}

/// Submit append transaction with pre-generated proofs
#[instrument(
    level = "debug",
    skip(context, proofs),
    fields(merkle_tree = ?context.merkle_tree)
)]
pub(crate) async fn submit_append_transaction<R: Rpc>(
    context: &BatchContext<R>,
    proofs: Vec<InstructionDataBatchAppendInputs>,
) -> Result<()> {
    if proofs.is_empty() {
        return Ok(());
    }
    
    let instructions: Vec<Instruction> = proofs
        .iter()
        .map(|data| create_batch_append_instruction(
            context.authority.pubkey(),
            context.derivation,
            context.merkle_tree,
            context.output_queue,
            context.epoch,
            data.try_to_vec().unwrap(),
        ))
        .collect();
    
    send_transaction_batch(context, instructions).await?;
    Ok(())
}
