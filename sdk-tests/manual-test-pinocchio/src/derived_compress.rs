//! Macro-derived compress and close implementation.
//!
//! This module contains the code that would be generated by the `#[light_program]` macro.
//! The dispatch function handles type-specific deserialization and compression.

use borsh::BorshDeserialize;
use light_account_pinocchio::{
    account_meta::CompressedAccountMetaNoLamportsNoAddress, prepare_account_for_compression,
    process_compress_pda_accounts_idempotent, CompressCtx, LightDiscriminator, LightSdkTypesError,
};
use pinocchio::{account_info::AccountInfo, program_error::ProgramError};

use crate::{account_loader::ZeroCopyRecord, pda::MinimalRecord};

/// MACRO-GENERATED: Discriminator-based dispatch function.
///
/// For each account type, this function:
/// 1. Reads the discriminator from account data
/// 2. Deserializes the account based on discriminator
/// 3. Calls prepare_account_for_compression with the deserialized data
fn compress_dispatch(
    account_info: &AccountInfo,
    meta: &CompressedAccountMetaNoLamportsNoAddress,
    index: usize,
    ctx: &mut CompressCtx<'_>,
) -> std::result::Result<(), LightSdkTypesError> {
    let data = account_info
        .try_borrow_data()
        .map_err(|_| LightSdkTypesError::Borsh)?;

    // Read discriminator from first 8 bytes
    let discriminator: [u8; 8] = data[..8]
        .try_into()
        .map_err(|_| LightSdkTypesError::InvalidInstructionData)?;

    match discriminator {
        d if d == MinimalRecord::LIGHT_DISCRIMINATOR => {
            // Borsh path: deserialize using try_from_slice
            let mut account_data =
                MinimalRecord::try_from_slice(&data[8..]).map_err(|_| LightSdkTypesError::Borsh)?;
            drop(data);

            // Call prepare with deserialized data
            prepare_account_for_compression(account_info, &mut account_data, meta, index, ctx)
        }
        d if d == ZeroCopyRecord::LIGHT_DISCRIMINATOR => {
            // Pod/Zero-copy path: read using bytemuck
            // The data is in fixed Pod layout, so we can directly cast it
            let record_bytes = &data[8..8 + core::mem::size_of::<ZeroCopyRecord>()];
            let mut account_data: ZeroCopyRecord = *bytemuck::from_bytes(record_bytes);
            drop(data);

            // Same prepare function works - hashing uses try_to_vec() which ZeroCopyRecord supports
            // via its BorshSerialize implementation
            prepare_account_for_compression(account_info, &mut account_data, meta, index, ctx)
        }
        // Unknown discriminator - skip (not an error, could be different account type)
        _ => Ok(()),
    }
}

/// MACRO-GENERATED: Process handler - just forwards to SDK function with dispatch.
pub fn process_compress_and_close(
    accounts: &[AccountInfo],
    instruction_data: &[u8],
) -> Result<(), ProgramError> {
    process_compress_pda_accounts_idempotent(
        accounts,
        instruction_data,
        compress_dispatch,
        crate::LIGHT_CPI_SIGNER,
        &crate::ID,
    )
    .map_err(|e| ProgramError::Custom(u32::from(e)))
}
